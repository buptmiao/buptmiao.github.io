---
layout: post
title: MYSQL设计与优化总结
tags: [about, Jekyll, theme, responsive]
comments: true
image:
  feature: 3.jpg
---

####MYSQL数据库设计篇

##1.目的

减少数据冗余
避免数据维护异常
节约存储空间
高效的访问

##2.步骤

需求分析 -- 
逻辑设计 -- 使用ER图对数据库进行逻辑建模
物理设计 -- 针对具体数据库的自身特点把逻辑设计转换为物理设计
维护优化 -- 新的需求进行建表、索引优化、大表拆分


###逻辑设计

数据操作异常和数据冗余:

操作异常：
	插入异常：如果某实体随着另一个实体的存在而存在。则存在插入异常
	更新异常: 如果更改表所对应的某个实体实例的单独属性时，需要将多行更新，那么久说这个表存在更新异常。
	删除异常：如果删除表的某一行来反映某实体实例失效时导致另一个不同实体实例信息丢失，那么这个表存在删除异常。
	插入异常和删除异常总是成对出现。
	数据冗余：相同的数据在多个地方存在，或者表中某个列可以由其他列计算得到，这样就说表中存在着数据冗余。
	所有操作异常都是针对一个表的设计中出现的问题。需要更改表的结构。

第一范式 ： 表示二维表
第二范式 ： 数据库的表中不存在非关键字段对任一候选关键字段的部分函数依赖

	所谓部分函数依赖是指组合关键字中的某一关键字决定非关键字的情况
	推论：所有单关键字的表都符合第二范式。

	若不符合此范式会存在以下问题：
		数据冗余
		插入、更新和删除异常
	解决方法：拆分成单关键字的表。建立关联关系表

第三范式： 数据库的表中不存在非关键字段对任意候选关键字段的传递函数依赖则符合第三范式
	
	单关键字和组合关键字都可能会出现。

	若不符合此范式会存在以下问题：

		数据冗余
		插入、更新和删除异常

	解决方法：拆分成单关键字的表并建立关联关系表

BC范式 ： 建立在第三范式上，不存在任何字段对任一候选关键字段的传递函数依赖则符合BC范式

	也就是说如果是复合关键字，则复合关键字之间也不能存在函数依赖关系。
	若不符合此范式会存在以下问题：

		数据冗余
		插入、更新和删除异常

	解决方法：缠粉成单关键字的表；

###物理设计

MySQL常用的存储引擎

MyISAM     不支持事务，支持并发插入的表级锁，主要应用SELECT ,INSERT，忌用，读写操作频繁
MRG_MYISAM 不支持事务，支持并发插入的表级锁，主要应用分段归档，数据仓库，忌用全局查找过多

Innodb 支持事务，支持MVCC(多版本并发控制)的行级锁，主要应用事务处理，忌用无，应用最多

Archive 不支持事务，支持行级锁，主要应用日志记录，只支持insert，select，忌用随机存储更新删除。优点是所需空间小，节约空间。

Ndb cluster 支持事务，行级锁，高可用性，一般应用在MySQL集群。内存数据库的一种

命名规范和数据类型选择

字段类型的选择原则：优先选择数字类型，其次是日期或二进制类型，最后是字符类型。对于相同级别的数据类型，应该优先选择占用空间小的数据类型。

选择原则：1、对数据进行比较排序时，数字类型最快。2、在数据库中，数据处理以页为单位，列的长度越小，利于性能提升。优化磁盘IO瓶颈

char与varchar如何选择

1，如果是固定长度，或者长度相差无几，使用char，否则应该考虑使用varchar
2，如果列中的最大数据长度小于50Bytes，则一般也考虑用char。varchar需要额外的字节（起始地址，长度等）

decimal与float如何选择

1，decimal用于存储精确数据，float用于存储非精确数据
2，由于float存储空间开销一般比decimal小故非精确选择float（精确到7位小数只需要4个字节，而精确到15位小数需要8字节）

时间类型如何选择

1，使用int来存储时间字段的优缺点

优点：字段长度比datetime小。
缺点：使用不方便，要进行函数转换。
限制：只能存储到2038-1-19 11：14:07。

2，需要存储的时间粒度

年月日时分秒周


其他注意事项

如何选择主键

	1，区分业务主键和数据库主键
	业务主键用于表示业务数据，进行表与表之间的关联；
	数据库主键为了优化数据存储（Innodb会生成6个字节的隐含主键）
	2，根据数据库的类型，考虑主键是否要顺序增长
	有些数据库是按主键的顺序逻辑存储的
	3，主键的字段类型所占空间要尽可能的小
	对于使用聚集索引方式存储的表，每个索引后都会附加主键信息。

避免使用外键约束 (外键可以用来保持数据的完整性)

	1，降低数据导入的效率 ，高并发中会影响性能
	2，增加维护成本
	3，虽然不建议使用外键约束，但是相关联的列上一定要建立索引

避免使用触发器

	1，降低数据导入的效率
	2，可能会出现意想不到的数据异常
	3，使业务逻辑变的复杂(业务变更时会不知道哪条语句有触发器)

关于预留字段

	1，无法准确的知道预留字段的类型。
	2，无法准确的知道预留字段中所存储的内容
	3，后期维护预留字段所要的成本，同增加一个字段所需要的成本是相同的。
	4，严禁使用预留字段。

反范式化
反范式化是针对范式化而言的，就是为咯额性能和读取效率的考虑而适当的对第三范式的要求进行违反，而允许存在少量的数据冗余，以空间换时间。

互联网中一般读写比例是3:1~4:1之间。所以写的时候多一点冗余可以提高读的效率。

反范式化的优点
	1，减少表的关联数量
	2，增加数据的读取效率
	3，反范式化一定要适度

###维护优化

1，维护数据字典
2，维护索引
3，维护表结构
3，在适当的时候对表进行水平拆分或垂直拆分 (在数据量过大的时候，查询会变的缓慢)

维护数据字典
	1，使用第三方工具
	2，使用备注字段，例如 CREATE TABLE customer(
							cust_id INT AUTO_INCREMENT NOT NULL COMMENT '自增ID'
						  )COMMENT '客户表'
	3，导出数据字典 SELECT a.table_name,b.TABLE_COMMENT,a.COLUMN_NAME,a.COLUMN_TYPE,a.COLUMN_COMMENT
					FROM information_schema.COLUMNS a JOIN information_schema.TABLES b
					ON a.table_schema=b.table_schema AND a.table_name = b.table_name
					WHERE a.table_name='customer'

维护索引
	1，出现在WHERE从句，GROUP BY 从句，ORDER BY从句中的列
	2，可选择性高的列要放在索引的前面
	3，索引中不要包括太长的数据类型

	注意事项
		1，索引并不是越多越好，过多的索引不但影响插入效率，还会降低读的效率(SQL优化器根据索引信息和统计信息选择合适的索引，所以如果索引太多，优化器在索引中选择，这个过程会降低效率)
		2，定期维护索引碎片 (磁盘碎片意思差不多)
		3，在SQL语句中不要使用强制索引关键字 (数据量的增大和需求的变更可能索引就不合适了，更改索引后其他人不知的情况下，使用强制索引会出错)

维护表结构
	1，MySQL5.6之后本身支持在线表结构的变更
	2，同时对数据字典进行维护
	3，控制表的宽度和大小，太宽的话需要垂直拆分

数据库中适合的操作
	1，批量操作 和 逐条操作
	2，禁止使用SELECT * 这样的查询，减少不需要的数据进而减少IO的操作
	3，控制使用用户自定义函数，一旦使用函数或者计算字段，则索引不起作用，低效
	4，不要是用数据库中的全文索引(需要建立索引文件，对中文支持不好，用专业搜索引擎代替)

表的垂直拆分和水平拆分
	垂直拆分  解决表的宽度的问题
	1，经常已查询的列放到一起
	2，text，blob等大字段拆分出到附加表中

	水平拆分  解决表的行太多的问题
	方法：对主键进行Hash



####数据库优化篇

数据库优化的目的
	避免出现页面访问错误
		1，由于数据库连接timeout产生页面5xx错误
		2，由于慢查询造成页面无法加载
		3，由于阻塞造成数据无法提交，服务器内部锁的原因，有时候大并发访问某个字段的时候，可能产生阻塞轻则影响性能，还会影响业务，数据库中有锁超时参数，阻塞超过一定的时间，这个事务就会被ROLLBACK，影响正常业务。
	增加数据库的稳定性
		很多数据库问题都是由于低效的查询引起的
	优化用户体验
		页面访问速度

数据库优化的层面

有高到低：SQL及索引，数据库表结构，系统配置，硬件

SQL及索引：(应用最多的方式)

根据需求写结构最好的SQL(有时候完成同样的功能有多种方式)和有效的索引

数据库表结构：

按照范式设计，设计简洁明了的表结构，降低冗余

系统配置：
应用在Linux，通常有一些限制，例如：TCP/IP文件数的限制，载荷文件数的限制，安全性的限制，需要对系统配置进行优化，最主要的是载荷文件数。因为数据库是基于文件的，查询需要打开文件，如果文件数超过了限制，则无法再打开，此时会进行频繁的IO操作。

硬件：(成本最高，效果最差，以上最重要)
CPU,内存，IO(SSD等)。CPU不是核数越多越好，MySQL会限制核数，很多查询只用到单核。

###SQL及索引优化

S如何发现有问题的SQL？
使用MySQL慢差日志对有效率问题的SQL进行监控
1,show variables like 'slow_query_log '
2,set global slow_query_log_file= '/home/mysql/sql_log/mysql-slow.log'
3,set global log_queries_not_using_indexex=on; //记录没有使用索引的查询
4,set global long_query_time=1;  //超过1秒，标记为慢查询

慢查日志包含的内容
	1，执行SQL的主机信息
	2，SQL的执行信息
	3，SQL的执行时间
	4，SQL的内容
需要借助工具分析慢查日志，生成报表：
mysqldumpslow。常用的工具，主要统计排序结果
pt-query-digest。更多内容
针对pt-query-digestD的结果
	1，通常为pt-query的前几个查询
	2，IO大的SQL，注意pt-query-digest中的Rows examine项表示扫描的行数
	3，未命中索引的SQL，注意pt-query-digest分析中Rows examine和Rows Send的对比

找到了SQL之后分析SQL查询
使用explain查询SQL的执行计划
explain返回各列的含义：
table:显示这一行的数据是关于哪张表的。
type: 这是重要的列，显示连接使用了何种类型，从最好到最差的连接类型为const(常数查找)、eq_reg(主键的范围查找)\ref()\range(主键的范围查抄)\index和ALL(表扫描)
possible_keys:显示可能应用在这张表中的索引。如果为空，没有可能的索引。
key:实际使用的索引。如果为NULL，则没有使用索引。
key_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好
ref：显示索引的哪一列被使用了，如果可能的话，是一个常数
rows：MYSQL认为必须检查的用来返回请求数据的行数
extra列需要注意的返回值：
	Using filesort：看到这个的时候，查询就需要优化了，MYSQL需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行，一般在ORDER BY、GROUP BY中。
	Using temporary：看到这个的时候，查询需要优化了。这里，MYSQL需要创建一个临时表来存储结果，这通常发生在对不同的列集进行ORDER BY上和GROUP BY上。


count()和Max()的优化方法：
对于Max可以用索引来优化。完全通过索引的信息查找到所需信息，叫做覆盖索引。
对于count()，在一条SQL中同时查出2006和2007年电影的数量---优化count()函数
SELECT COUNT(release_year='2006' OR NULL) AS '2006',COUNT(release_year='2007' OR NULL) AS '2007' FROM film;

子查询优化成连接，需要注意数据重复，要使用distinct关键字

GROUP BY 优化方法：有时需要改成：用子查询分组。

Limit查询的优化：
1，使用主键或索引进行排序。
2，记录上次返回的主键，在下次查询时使用主键过滤


###索引优化

1，在where从句，group by从句，order by 从句，on 从句中出现的列
2，索引字段越小越好
3，离散度大的列放在联合索引的前面
	如何判断离散度 select count；

使用工具进行索引的维护和优化
pt-duplicate-key-checker工具检查重复及冗余索引
pt-duplicate-key-checker -u root -p '' -h 127.0.0.1//查看重复索引
pt-index-usage -uroot -p '' mysql-slow.log  //查看哪些索引使用频率低，可以删除

###数据库结构优化

合适的数据类型
	1，使用int来存储日期时间，利用FROM_UNIXTIME(),UNIX_TIMESTAMP()两个函数来进行转换 INSERT ... UNIX_TIMESTAMP('2014-06-01 13:12:00')
						SELECT FROM_UNIXTIME(timestr) ...;
	2，使用bigint来存储IP地址，利用INET_ATON(),INET_NTOA()两个函数来进行转换
	INSERT ... INET_ATON('192.168.0.1');SELECT INET_NTOA(ip)

表的范式化和反范式化，第三范式化最常用

表的垂直

水平拆分
前后台分开，前台用拆分的表，后台使用汇总表


###系统优化
操作系统配置优化

1，网络方面的配置，要修改/etc/sysctl.conf文件
#增加tcp支持的队列数
 net.ipv4.tcp_max_syn_backlog = 65535
#减少断开连接时，资源回收  
 net.ipv4.tcp_max_tw_buckets = 8000
 net.ipv4.tcp_tw_reuse = 1
 net.ipv4.tcp_tw_recycle = 1
 net.ipv4.tcp_fin_timeout = 10
2，打开文件数的配置
使用 ulimit -a查看目录的各位限制，可以修改/etc/security/limits.conf文件
* soft nofile 65535
* hard nofile 65535
除此之外最好在MySQL服务骑上关闭iptables ,selinux等防火墙软件


MySQL本身配置的优化

在大多数情况下配置文件位于/etc/my.cnf或者/etc/mysql/my.cnf
windows下可能在C:/windows/my.ini文件，MySQL查找配置文件的顺序可以通过以下方法获得 $ /usr/sbin/mysqld --verbose --help|grep -A 1 'Default options' 会得到一系列顺序路径，后面的会覆盖前面的，也就是权限高一点

常用参数说明：
innodb_buffer_pool_size: 非常重要的参数，用于配置Innodb的缓冲池，如果数据库中只有Innodb表，则推荐配置量为总内存的75%。

SELECT ENGINE,ROUND(SUM(data_length + index_length)/1024/1024,1) AS 'Total MB'
FROM INFORMATION_SCHEMA.TABLES
WHERE table_schema not in ('information_schema','performance_schema')
GROUP BY ENGINE;

所设置的Innodb_buffer_pool_size >= Total MB

innodb_buffer_pool_instances:MySQL 5.5中新增加的参数，可以控制缓冲池的个数，默认情况下只有一个。如果只有一个，可能增加阻塞的频率，这可以提高并发性。

innodb_log_buffer_size:innodb log缓冲的大小，由于日志最长每秒钟就会刷新所以一般不用太大。
innodb_flush_log_at_trx_commit:关键参数，对innodb的IO效率影响很大。默认值为1，可以取0,1,2三个值，一般设置为2效率高些安全性稍低,如果数据安全性要求比较高则使用1。
innodb_read_io_threads
innodb_write_io_threads:这两个决定了Innodb读写的IO进程数，默认为4，可以根据核数调整

innodb_file_per_table ：关键参数，控制Innodb每一个表使用独立的表空间，默认为OFF，也就是所有的表都会建立在共享表空间中。这种情况，共享表空间的IO会达到一个瓶颈，共享表空间由于只有一个文件，并发写入的时候效率大大降低。另外，共享表空间无法单独收缩，如果删除一个不使用的表，想收缩表空间，只能导出再导入。如果使用独立的表空间，删除表时候会马上回收资源，另外，由于多个文件，会提高并发效率。

innodb_stats_on_metadata:决定MySQL在什么情况下回刷新innodb表的统计信息。好多操作比如select等可能会需要表的统计信息，所以在另一些情况下需要对表的统计信息进行刷新，以保持优化器正确使用到合适的索引，但是如果刷新频率过高，不必要。需要对此参数设置为OFF，避免在查询系统表，show create table，show table status等的时候对表的统计信息进行刷新，而是人为的刷新。


第三方工具配置：
	Percon Configuration Wizard
	https://tools.percona.com/wizard
	不能完全依赖向导，可供参考

###硬件优化
CPU选择:一般是用单核高速的CPU，不要超过32核，会反而更差
Disk IO优化
RAID0:把多个磁盘连接成一个硬盘使用，IO级别最好，但是如果一个损坏就损坏了，安全性不好
RAID1：镜像，至少两个磁盘，存储的数据相同。IO效果差，安全性高
RAID5：多个硬盘合并成一个逻辑盘使用，数据读写时会建立奇偶校验信息，存储在不同磁盘上，当数据损坏后，利用剩下的数据和奇偶校验信息去恢复被损坏的数据
RAID0+1：就是RAID1和RAID0的结合。同时具备两个级别的优缺点。一般选这个级别。



####关于MySQL索引背后的数据结构与算法原理

基本数据结构是B+TREE。

索引是与存储引擎密切相关的。

MYISAM索引：非聚集索引，索引文件与数据文件是分离的，索引文件保存数据的地址。
可以没有主键。在MYISAM中，主索引和辅助索引在结构上没有任何区别，只是主索引要求key唯一，而辅助索引的key可以重复

Innodb索引：聚集索引，表数据文件本身就是按B+TREE组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此Innodb表数据文件本身就是主索引。所以InnoDB必须要有主键，如果没有显示的指定主键,MYSQL会自动选择一个可以唯一标示行的列作为主键，如果不存在这种行，MYSQL自动的生成一个6字节的长整型隐含字段作为主键。 另外，Innodb的辅助索引data域存储相应记录主键的值而不是地址。Innodb索引的所有辅助索引都是以主键作为data域。检索两遍。

了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InooDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都医用主索引，过长的主索引会令辅助索引变得过大。另外，用非单调的字段作为主键在InnoDB中不是一个好主意，因为InnoDB数据文件本身是一颗B+tree，非单调的主键会造成在插入新纪录时数据文件为了维持B+tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好地选择。


在基于对索引的原理的理解基础上，对索引进行优化。

MySQL的优化主要分为结构优化和查询优化。

最左前缀原理与相关优化

1，全列匹配

当按照索引中所有列进行精确匹配（精确是指"="或"IN"匹配），索引可以被用到。理论上索引对顺序是敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用合适的索引
2，最左前缀匹配  type=ref。
只有索引左边的连续几列被使用到，使用的key_len要少
3，查询条件用到了索引中列的精确匹配，但是中间某个条件未提供。
则只是用空缺前面的索引列，后面的索引列被给出的条件过滤。优化方法：可以增加一个辅助索引（使用给出的索引列），还可以使用一种称之为"隔离列"的优化方法，将空缺的坑填上。
加入title的可能值很少，可以使用IN填坑。
EXPLAIN SELECT * FROM employees.titles
WHERE emp_no='10001'
AND title IN ('Senior Engineer', 'Staff', 'Engineer', 'Senior Staff', 'Assistant Engineer', 'Technique Leader', 'Manager')
AND from_date='1986-06-26';
则优化后的key_len为59. 可能执行了一个range查询，但是通过SHOW PROFILES；比较后发现性能提高。
如果经过emp_no筛选后余下很多数据，则后者性能优势会更加明显。如果title的值很多，用填坑不合适，必须建立辅助索引。
4，查询条件没有指定索引第一列。
使用不到索引
5，匹配某列的前缀字符串。
如果通配符%不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀
6，范围查询。
范围列可以用到索引（必须是最左前缀）。但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。explain无法区分范围索引和多值匹配，因为在type中这两者都显示为range。同时，用了“between”并不意味着就是范围查询。
7，查询条件中含有函数或表达式
如果查询条件中含有函数或表达式，则MySQL不会为这列使用索引（虽然某些在数学意义上可以使用）

索引的选择性计算：
SELECT count(DISTINCT(title))/count(8) AS Selectivity FROM titles;
在设计索引的时候，如果一个列选择性太低，可以两个列，或者第二个列的前几个字节left(col2,4)。
前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于ORDER BY 和 GROUP BY，也不能用于covering index（即当索引文件本身包含查询所需全部数据时，不再访问数据文件本身）。

InnoDB的主键选择与插入优化。
使用InnoDB时候，如果没有特别的需要，永远使用一个与业务无关的自增字段作为主键。从数据库索引优化的角度看，使用InnoDB引擎而不使用自增主键绝对是一个糟糕的主意。如果主键是学号或者身份证号，那插入的位置是随机的，造成数据移动。是的索引结构不够紧凑，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。


